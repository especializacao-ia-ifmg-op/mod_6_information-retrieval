{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especialização em Inteligência Artificial<br>\n",
    "Recuperação de Informação<br>\n",
    "Atividade 2 - Implementação do Indexador<br>\n",
    "Prof. Moisés<br>\n",
    "Aluno: Fernando dos Santos Alves Fernandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexador\n",
    "Ainda no contexto definido na implementação do coletor (Atividade 1), foi implementado o indexador, utilizando como abordagem uma lista invertida.\n",
    "Para a avaliar a força da palavra ou termo, foram considerados os valores de f(K), F(K) e n(K), implementados em sala de aula, em que o K é a chave ou o termo indexado na lista invertida. Para esse trabalho, o IDF também foi calculado para cada um dos tokens. \n",
    "O peso f(K), também conhecido como TF (_Term Frequency_, TF(t,d)) é o número de ocorrências do termo t no documento d. F(K) é o total de ocorrências do termo t (ou chave K), considerando todos os documentos em que ele é encontrado. O peso n(K), que também pode ser encontrado na literatura como DF(t), ou _Document Frequency_ do termo t, corresponde ao número de documentos em que a chave K ocorre. O IDF(t) (_Inverse Document Frequency_, do termo t) é o peso do termo que considera o número de documentos coletados (N) e o IDF do termo e pode ser calculado como $log(N/DF(t))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A implementação completa do indexador pode ser vista a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "class Indexador:\n",
    "    def __init__(self, coletor) -> None:\n",
    "        self.coletor = coletor\n",
    "        #self.tokenized_titles = []\n",
    "        self.stop_words = set(stopwords.words('portuguese'))\n",
    "        self.inverted_index = {}\n",
    "        self.F = {}\n",
    "        \n",
    "    def inverted_index_generator(self):\n",
    "        for object in self.coletor.objects_url:\n",
    "            tokenized_titles = []\n",
    "            for title in object.titles: # Os h2!\n",
    "                tokens = [token for token in [token.lower().replace('\\u200b', '') for token in nltk.word_tokenize(title.text) if token.lower() not in self.stop_words] if token.isalnum()] # Lista de palavras relevantes!\n",
    "                tokenized_titles.extend(tokens)\n",
    "\n",
    "            f = {}\n",
    "            for token in tokenized_titles:\n",
    "                if token not in f:\n",
    "                    f[token] = 1\n",
    "                    if token not in self.F:\n",
    "                        self.F[token] = 0\n",
    "                else:\n",
    "                    f[token] += 1\n",
    "            \n",
    "            # Term Frequency:\n",
    "            #         / 1 + log(f) if fi,j(k) > 0, \n",
    "            #   tf = { \n",
    "            #         \\ 0, otherwise\n",
    "            #\n",
    "            # Inverse Document Frequency:\n",
    "            #   idf = log N / ni\n",
    "            #   N = len((self.coletor.objects_url)\n",
    "            \n",
    "            for token in tokenized_titles: # f(k), F(k), n(k), idf\n",
    "                self.inverted_index.setdefault(token, {}).update({object.url: [f[token], self.F[token], 0, 0]}) # Link e peso do token!\n",
    "                \n",
    "            for token in self.inverted_index.keys():\n",
    "                if token in f:\n",
    "                    self.F[token] += f[token]\n",
    "                    \n",
    "    def update_F(self):\n",
    "        for token in self.inverted_index.keys():\n",
    "            for object_url in self.inverted_index[token].keys():\n",
    "                self.inverted_index[token][object_url][1] = self.F[token] # F(k)\n",
    "                self.inverted_index[token][object_url][2] = len(self.inverted_index[token].keys()) # n(k)\n",
    "                self.inverted_index[token][object_url][3] = math.log(len(self.coletor.objects_url)/self.inverted_index[token][object_url][2]) # idf(k)\n",
    "            \n",
    "    def save_index(self):\n",
    "        filename = self.coletor.codigo\n",
    "        with open(f\"index-{filename}.json\", 'w') as file:\n",
    "            json.dump(self.inverted_index, file, indent=4)\n",
    "        print(f'[indexador] index-{filename}.json = {len(self.inverted_index.keys())}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d87e67db777b4b0db676edb6578e0de57a75ced3517006e5561808a12abc48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
